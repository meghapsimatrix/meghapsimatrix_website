---
title: "wildmeta"
author:
- name:
    given: Megha
    family: Joshi
- name:
    given: James E. 
    family: Pustejovsky
- name:
    given: Pierce
    family: Cappelli
date: 2024-07-26
image: wildmeta_hex.png
links:
- text: CRAN
  url: https://cran.r-project.org/package=wildmeta
- text: Website
  url: https://meghapsimatrix.github.io/wildmeta/
- icon: github
  url: https://github.com/meghapsimatrix/wildmeta/
citation:
  type: software
  doi: 10.32614/CRAN.package.wildmeta
  medium: R package
  note: R package
  version: 0.3.2
  issued: '2023-03-08T00:00:00Z'
---

Typical methods to conduct meta-analysis---pooling effect sizes or analyzing moderating effects with meta-regression---work under the assumption that the effect size estimates are independent. However, primary studies often report multiple estimates of effect sizes. Presence of multiple effect sizes leads to dependence as the estimates within each study are likely correlated (e.g., because the same participants provide multiple outcome scores). The increasingly popular method to handle such dependence, robust variance estimation (RVE), results in inflated Type 1 error rate when the number of studies is small (Hedges, Tipton & Johnson, 2010; Tipton, 2015).

Tipton (2015) and Tipton & Pustejovsky (2015) examined several small sample correction methods. Tipton (2015) recommended CR2 type correction for RVE as well as the use of Satterthwaite degrees of freedom for single coefficient tests. Tipton & Pustejovsky (2015) examined corrections for [multiple-contrast hypothesis tests](https://cran.r-project.org/web/packages/clubSandwich/vignettes/Wald-tests-in-clubSandwich.html). The authors found that the HTZ test, which is an extension of the CR2 correction method with the Satterthwaite degrees of freedom, controlled Type 1 error rate adequately even when the number of studies was small. However, Joshi, Pustejovsky & Beretvas (2021) showed, through simulations, that the HTZ test can be conservative. We examined another method, cluster wild bootstrapping (CWB), that has been studied in the econometrics literature but not in the meta-analytic context. The results of the simulations from Joshi, Pustejovsky & Beretvas (2021) showed that CWB adequately controlled for Type 1 error rate and had more power than the HTZ test especially for multiple-contrast hypothesis tests.The goal of this package is to provide applied meta-analytic researchers a function with which they can conduct single coefficient tests or multiple-contrast hypothesis tests using cluster wild bootstrapping.
